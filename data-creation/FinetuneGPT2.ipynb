{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HZ5nTz3QI8EB"},"outputs":[],"source":["!pip install -q transformers torch torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2766,"status":"ok","timestamp":1646271209162,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"eY9a2Os6L9Yt","outputId":"8a737eb7-c504-4d95-f31e-09788b44d4d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","\n","model_checkpoint = \"gpt2\"\n","batch_size = 2\n","\n","with open('100KStories.csv', 'rb') as csv_file:\n","    csv_data = pd.read_csv(csv_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1646271217739,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"wkfiMOQyUWzz","outputId":"4f35b726-4df4-4418-ad7c-551e90bf00a3"},"outputs":[],"source":["train_set = csv_data[:500]\n","train_set_input = train_set['sentence1'] + ' ' + train_set['sentence2'] + ' ' + train_set['sentence3']\n","train_set_output = train_set['sentence4'] + ' ' + train_set['sentence5'] \n","print(train_set_input.values.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1473,"status":"ok","timestamp":1646275734616,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"529doWX6W6cu","outputId":"b2c3402a-aa17-4d43-c81b-5fa788857e69"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config\n","tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n","\n","class GPT2Dataset(Dataset):\n","\n","  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n","    train_set_input = txt_list['sentence1'] + ' ' + txt_list['sentence2'] + ' ' + txt_list['sentence3']\n","    train_set_output = txt_list['sentence4'] + ' ' + txt_list['sentence5'] \n","    train_set_input = train_set_input.values.tolist()\n","    train_set_output = train_set_output.values.tolist()\n","    self.tokenizer = tokenizer\n","    self.input_ids = []\n","    self.attn_masks = []\n","    self.label_ids = []\n","    for i in range(len(train_set_input)):\n","      input_encodings_dict = tokenizer('<|startoftext|>'+ train_set_input[i]+ '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n","      output_encodings_dict = tokenizer('<|startoftext|>' + train_set_output[i] + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n","      print(tokenizer.decode(output_encodings_dict[\"input_ids\"]))\n","      self.input_ids.append(torch.tensor(input_encodings_dict.get('input_ids')))\n","      self.label_ids.append(torch.tensor(output_encodings_dict.get('input_ids')))\n","      self.attn_masks.append(torch.tensor(input_encodings_dict['attention_mask']))\n","    \n","  def __len__(self):\n","    return len(self.input_ids)\n","\n","  def __getitem__(self, idx):\n","    return self.input_ids[idx], self.attn_masks[idx], self.label_ids[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1q8R_B8hM5azuhRxOkQx8uvNk2EI_lRSU"},"executionInfo":{"elapsed":4372,"status":"ok","timestamp":1646275743044,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"N2O8H9yTompE","outputId":"5c9fcb96-79ce-4835-aaed-75586592c75b"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["dataset = GPT2Dataset(train_set, tokenizer, max_length=768)\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yuQaMmCprJN"},"outputs":[],"source":["train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFW7o9g3p6K7"},"outputs":[],"source":["import numpy as np\n","import random\n","# I'm not really doing anything with the config buheret\n","configuration = GPT2Config.from_pretrained(model_checkpoint, output_hidden_states=False)\n","\n","# instantiate the model\n","model = GPT2LMHeadModel.from_pretrained(model_checkpoint, config=configuration)\n","\n","# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n","# otherwise the tokenizer and model tensors won't match up\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Tell pytorch to run this model on the GPU.\n","device = torch.device(\"cuda\")\n","model.cuda()\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1646275782242,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"_J4hELUpqVXE","outputId":"a81abc71-3f77-4105-ded2-d8be05b3aee2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["import datetime\n","import time\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","epochs = 3\n","learning_rate = 5e-4\n","warmup_steps = 1e2\n","epsilon = 1e-8\n","\n","# this produces sample output every 100 steps\n","sample_every = 100\n","optimizer = AdamW(model.parameters(),\n","                  lr = learning_rate,\n","                  eps = epsilon\n","                )\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","# This changes the learning rate as the training loop progresses\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = warmup_steps, \n","                                            num_training_steps = total_steps)\n","\n","def format_time(elapsed):\n","    return str(datetime.timedelta(seconds=int(round((elapsed)))))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":621048,"status":"ok","timestamp":1646276410683,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"vCPohrZ-CTWu","outputId":"345f99a3-edb5-4d00-f4da-1e5be68128f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["  Batch   100  of    200. Loss: 0.21794334053993225.   Elapsed: 0:01:36.\n","0:  bipartisanIn first he she he...\n","\n","  Average training loss: 0.55\n","  Training epoch took: 0:03:11\n","\n","Running Validation...\n","  Validation Loss: 0.21\n","  Validation took: 0:00:15\n","\n","======== Epoch 2 / 3 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["  Batch   100  of    200. Loss: 0.2036871463060379.   Elapsed: 0:01:36.\n","0:  increasingI, his.. the had them.. had to,. it\n","\n","  Average training loss: 0.20\n","  Training epoch took: 0:03:11\n","\n","Running Validation...\n","  Validation Loss: 0.21\n","  Validation took: 0:00:15\n","\n","======== Epoch 3 / 3 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["  Batch   100  of    200. Loss: 0.18419426679611206.   Elapsed: 0:01:36.\n","0: dayJ was it the.!. on to the the. was. it!\n","\n","  Average training loss: 0.18\n","  Training epoch took: 0:03:15\n","\n","Running Validation...\n","  Validation Loss: 0.21\n","  Validation took: 0:00:15\n","\n","Training complete!\n","Total training took 0:10:22 (h:mm:ss)\n"]}],"source":["torch.cuda.empty_cache()\n","import gc\n","gc.collect()\n","total_t0 = time.time()\n","\n","training_stats = []\n","\n","model = model.to(device)\n","\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","\n","        b_input_ids = batch[0].to(device)\n","        b_masks = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        outputs = model(  b_input_ids,\n","                          labels=b_labels, \n","                          attention_mask = b_masks,\n","                          token_type_ids=None\n","                        )\n","\n","        loss = outputs[0]  \n","\n","        batch_loss = loss.item()\n","        total_train_loss += batch_loss\n","\n","        # Get sample every x batches.\n","        if step % sample_every == 0 and not step == 0:\n","\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n","\n","            model.eval()\n","\n","            sample_outputs = model.generate(\n","                                    bos_token_id=random.randint(1,30000),\n","                                    do_sample=True,   \n","                                    top_k=50, \n","                                    max_length = 200,\n","                                    top_p=0.95, \n","                                    num_return_sequences=1\n","                                )\n","            for i, sample_output in enumerate(sample_outputs):\n","                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n","            \n","            model.train()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)       \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    model.eval()\n","\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        b_input_ids = batch[0].to(device)\n","        b_masks = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        with torch.no_grad():        \n","\n","            outputs  = model(b_input_ids, \n","#                            token_type_ids=None, \n","                             attention_mask = b_masks,\n","                            labels=b_labels)\n","          \n","            loss = outputs[0]  \n","            \n","        batch_loss = loss.item()\n","        total_eval_loss += batch_loss        \n","\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    validation_time = format_time(time.time() - t0)    \n","\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2126,"status":"ok","timestamp":1646202249600,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"YkLRa1wXTARv","outputId":"bdb6102d-6319-4a2f-f61b-da2990c81e06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to ./model_save/\n"]},{"data":{"text/plain":["('./model_save/tokenizer_config.json',\n"," './model_save/special_tokens_map.json',\n"," './model_save/vocab.json',\n"," './model_save/merges.txt',\n"," './model_save/added_tokens.json')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","output_dir = './model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1646202309567,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"pbXwqOiOTX9D","outputId":"7c2b46df-da50-444f-ab39-64d9e74d0a35"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 499796K\n","-rw-r--r-- 1 root root      1K Mar  2 06:24 added_tokens.json\n","-rw-r--r-- 1 root root      1K Mar  2 06:24 config.json\n","-rw-r--r-- 1 root root    446K Mar  2 06:24 merges.txt\n","-rw-r--r-- 1 root root 498448K Mar  2 06:24 pytorch_model.bin\n","-rw-r--r-- 1 root root      1K Mar  2 06:24 special_tokens_map.json\n","-rw-r--r-- 1 root root      1K Mar  2 06:24 tokenizer_config.json\n","-rw-r--r-- 1 root root    878K Mar  2 06:24 vocab.json\n","-rw-r--r-- 1 root root 487M Mar  2 06:24 ./model_save/pytorch_model.bin\n"]}],"source":["!ls -l --block-size=K ./model_save/\n","!ls -l --block-size=M ./model_save/pytorch_model.bin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QbMnOQbTidu"},"outputs":[],"source":["data_dir = os.path.join('/content/drive/', \"'My Drive'\",\"'Colab Notebooks'\")\n","!cp -r ./model_save/ $data_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":914,"referenced_widgets":["173f289902354be38a8f0f300fa349f9","d2348d71a79546b3a048120f9f4ef6bd","f8385a8265b44c94b000c94ace9f35c4","4334a4b1deb243dc83b52b95b7105ac8","576cdc559b364016878fac77f2392ea7","c42e7081caa049c19b188b10c4f67d79","2d470645c71b4656915252192301c77f","f225d643bef84e26a056ce1e7a315364","de93c4b320774770837b951739958424","ea32840fc60043838abf2397affb6a48","09502bfd9cb943aba4e1afdab3990600","5db8d43286e8438f8e8e5388936add42","d6f589f5accf45feb78e285498f4cbb5","8bee1355537d459bb9d265e83795c7e5","dec2de8a94fc4820966ce55c2ca9d8d6","6aece5f3978b44b9928e842323a93915","5e8a65133d74470dac332b5a80a2208e"]},"executionInfo":{"elapsed":3843,"status":"error","timestamp":1646202930736,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"U5TynfYtVmEF","outputId":"1ad23ba9-9ced-4f41-d892-1eb273e660e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8820,"status":"ok","timestamp":1646202965638,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"5HgrKnVqV6Ww","outputId":"b8ada8ec-1dbc-4c6c-cb22-38e584952e91"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-470\n","Use 'apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  git-lfs\n","0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 2,129 kB of archives.\n","After this operation, 7,662 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n","Fetched 2,129 kB in 2s (882 kB/s)\n","Selecting previously unselected package git-lfs.\n","(Reading database ... 155320 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n","Unpacking git-lfs (2.3.4-1) ...\n","Setting up git-lfs (2.3.4-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}],"source":["!apt install git-lfs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["e9d34826bf3c45068ecc77156f45077a","e32c662e83304ecc8b0679a1e078654c","df6e5b2ff4004e88967b9bf0d9bab371","67462b829f134d50a932ec0aff9bd615","02f8dbaba159423fa0929b4bec0b88fe","47c5f850a4f547d2853fde8e405ff29f","5840e3bd1a174750a63285ec1294f6ee","c0f0dfeb98df48e4850ef4e4a1c82a6b","c00db684dd334f6ba34be4d1e5f23c73","ba34b82d87cb4d9d9de9b41e0c28817a","e9fe45d20b9b460c8a3bb551748b5e32"]},"executionInfo":{"elapsed":452389,"status":"ok","timestamp":1646203425500,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"ExvpzLWpV2Jx","outputId":"82e2eb6a-9921-4092-a6fe-a517ec6070da"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n","  FutureWarning,\n","Cloning https://huggingface.co/msintaha/gpt2-finetuned-rocstories into local empty directory.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9d34826bf3c45068ecc77156f45077a","version_major":2,"version_minor":0},"text/plain":["Upload file pytorch_model.bin:   0%|          | 3.38k/487M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/msintaha/gpt2-finetuned-rocstories\n","   ca2bf84..3adbeee  main -> main\n","\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'https://huggingface.co/msintaha/gpt2-finetuned-rocstories/commit/3adbeeef5411c9539192d88bb5a236ae97731b0e'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["model_name = \"boundmc-finetuned-rocstories\"\n","model.push_to_hub(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["1488c518f9984ed389262875e43d293e","516bde9fa2494ad7947903db0bfd24e8","b51345949dbf4faaa6fc521740af2dd7","a012b7b984b34e2ea331ba2b25059db9","5cee9e9eef1c427c80b59f0b8ebb1ca3","3e293a541a6c48a99db8a789c8826238","3e17e0f9674a4d52beb7b414f85709ea","fbaf95a972544978b516c6731fcaf6e5","7b980d8f73b54043b07c29197df0a710","ea27026425a348e58cc0c8a7f6c4eba7","fd7d51ca6b2e4912a8da41ac1dcaba35","abe9fa838080462ca3e783be5232605c","aca10c635c8a4a82976db9605a6a8620","467376e29a8249b29d663a29acda3a96","6cc955a3133a4900a90a7b5944276787","3307ff0efdec413fba1d5fb843e0c5c4","d6aa1b63db0b433297f1b309135b6c16","829f097dfb524d21b85fc6dfa55e1d66","9b268faba67e45bea2c3f3f73ae0d950","358532f284bf4903b3dd4bb4015db5c2","115371f07ef640b4b7e61c2022f3b1a7","20ad5c01320240fd89408645b714a5c0"]},"executionInfo":{"elapsed":264500,"status":"ok","timestamp":1646204578679,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"TTNsjdydYXhy","outputId":"b1f139e4-7d64-4a90-8815-1a72ea81d6ec"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n","  FutureWarning,\n","Cloning https://huggingface.co/msintaha/gpt2-finetuned-rocstories into local empty directory.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1488c518f9984ed389262875e43d293e","version_major":2,"version_minor":0},"text/plain":["Download file pytorch_model.bin:   0%|          | 1.83k/487M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abe9fa838080462ca3e783be5232605c","version_major":2,"version_minor":0},"text/plain":["Clean file pytorch_model.bin:   0%|          | 1.00k/487M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(None,)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"msintaha/{}\".format(model_name), push_to_hub=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":590,"status":"ok","timestamp":1646276734799,"user":{"displayName":"Mifta Sintaha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiokbpSmhfuRgSwBG1hJ20_TKDf4LHCwsVoSlRjUQ=s64","userId":"09610869912023947881"},"user_tz":480},"id":"ykQ4CD7mT5yc","outputId":"dedafdea-c38d-4589-80d2-05bbe09973ac"},"outputs":[],"source":["model.eval()\n","\n","prompt = \"<|startoftext|>Gloria wanted to find a special new dress for her anniversary dinner.\"\n","\n","generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n","generated = generated.to(device)\n","\n","print(generated)\n","\n","sample_outputs = model.generate(\n","                                generated, \n","                                #bos_token_id=random.randint(1,30000),\n","                                do_sample=True,   \n","                                top_k=50, \n","                                max_length = 500,\n","                                top_p=0.95, \n","                                num_return_sequences=5\n","                                )\n","\n","for i, sample_output in enumerate(sample_outputs):\n","  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"FinetuneGPT2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02f8dbaba159423fa0929b4bec0b88fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9fe45d20b9b460c8a3bb551748b5e32","placeholder":"​","style":"IPY_MODEL_ba34b82d87cb4d9d9de9b41e0c28817a","value":" 487M/487M [07:09&lt;00:00, 864kB/s]"}},"09502bfd9cb943aba4e1afdab3990600":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"115371f07ef640b4b7e61c2022f3b1a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1488c518f9984ed389262875e43d293e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b51345949dbf4faaa6fc521740af2dd7","IPY_MODEL_a012b7b984b34e2ea331ba2b25059db9","IPY_MODEL_5cee9e9eef1c427c80b59f0b8ebb1ca3"],"layout":"IPY_MODEL_516bde9fa2494ad7947903db0bfd24e8"}},"173f289902354be38a8f0f300fa349f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f8385a8265b44c94b000c94ace9f35c4","IPY_MODEL_4334a4b1deb243dc83b52b95b7105ac8","IPY_MODEL_576cdc559b364016878fac77f2392ea7","IPY_MODEL_c42e7081caa049c19b188b10c4f67d79","IPY_MODEL_2d470645c71b4656915252192301c77f"],"layout":"IPY_MODEL_d2348d71a79546b3a048120f9f4ef6bd"}},"20ad5c01320240fd89408645b714a5c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d470645c71b4656915252192301c77f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Use password","disabled":false,"icon":"","layout":"IPY_MODEL_5e8a65133d74470dac332b5a80a2208e","style":"IPY_MODEL_6aece5f3978b44b9928e842323a93915","tooltip":""}},"3307ff0efdec413fba1d5fb843e0c5c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20ad5c01320240fd89408645b714a5c0","placeholder":"​","style":"IPY_MODEL_115371f07ef640b4b7e61c2022f3b1a7","value":" 487M/487M [01:02&lt;00:00, 8.27MB/s]"}},"358532f284bf4903b3dd4bb4015db5c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e17e0f9674a4d52beb7b414f85709ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e293a541a6c48a99db8a789c8826238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4334a4b1deb243dc83b52b95b7105ac8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_09502bfd9cb943aba4e1afdab3990600","placeholder":"​","style":"IPY_MODEL_ea32840fc60043838abf2397affb6a48","value":""}},"467376e29a8249b29d663a29acda3a96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_829f097dfb524d21b85fc6dfa55e1d66","placeholder":"​","style":"IPY_MODEL_d6aa1b63db0b433297f1b309135b6c16","value":"Clean file pytorch_model.bin: 100%"}},"47c5f850a4f547d2853fde8e405ff29f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"516bde9fa2494ad7947903db0bfd24e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"576cdc559b364016878fac77f2392ea7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_d6f589f5accf45feb78e285498f4cbb5","style":"IPY_MODEL_5db8d43286e8438f8e8e5388936add42","tooltip":""}},"5840e3bd1a174750a63285ec1294f6ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cee9e9eef1c427c80b59f0b8ebb1ca3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd7d51ca6b2e4912a8da41ac1dcaba35","placeholder":"​","style":"IPY_MODEL_ea27026425a348e58cc0c8a7f6c4eba7","value":" 487M/487M [04:03&lt;00:00, 106kB/s]"}},"5db8d43286e8438f8e8e5388936add42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"5e8a65133d74470dac332b5a80a2208e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67462b829f134d50a932ec0aff9bd615":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c00db684dd334f6ba34be4d1e5f23c73","max":510409961,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0f0dfeb98df48e4850ef4e4a1c82a6b","value":510409961}},"6aece5f3978b44b9928e842323a93915":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"6cc955a3133a4900a90a7b5944276787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_358532f284bf4903b3dd4bb4015db5c2","max":510409961,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b268faba67e45bea2c3f3f73ae0d950","value":510409961}},"7b980d8f73b54043b07c29197df0a710":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"829f097dfb524d21b85fc6dfa55e1d66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bee1355537d459bb9d265e83795c7e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b268faba67e45bea2c3f3f73ae0d950":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a012b7b984b34e2ea331ba2b25059db9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b980d8f73b54043b07c29197df0a710","max":510409961,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbaf95a972544978b516c6731fcaf6e5","value":510409961}},"abe9fa838080462ca3e783be5232605c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_467376e29a8249b29d663a29acda3a96","IPY_MODEL_6cc955a3133a4900a90a7b5944276787","IPY_MODEL_3307ff0efdec413fba1d5fb843e0c5c4"],"layout":"IPY_MODEL_aca10c635c8a4a82976db9605a6a8620"}},"aca10c635c8a4a82976db9605a6a8620":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b51345949dbf4faaa6fc521740af2dd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e17e0f9674a4d52beb7b414f85709ea","placeholder":"​","style":"IPY_MODEL_3e293a541a6c48a99db8a789c8826238","value":"Download file pytorch_model.bin: 100%"}},"ba34b82d87cb4d9d9de9b41e0c28817a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c00db684dd334f6ba34be4d1e5f23c73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0f0dfeb98df48e4850ef4e4a1c82a6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c42e7081caa049c19b188b10c4f67d79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dec2de8a94fc4820966ce55c2ca9d8d6","placeholder":"​","style":"IPY_MODEL_8bee1355537d459bb9d265e83795c7e5","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated 'notebooks' token with 'write' access, that you can then easily reuse for all notebooks.\n<br>\n<i>Logging in with your username and password is deprecated and won't be possible anymore in the near future. You can still use them for now by clicking below.</i>\n</center>"}},"d2348d71a79546b3a048120f9f4ef6bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"d6aa1b63db0b433297f1b309135b6c16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6f589f5accf45feb78e285498f4cbb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de93c4b320774770837b951739958424":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec2de8a94fc4820966ce55c2ca9d8d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6e5b2ff4004e88967b9bf0d9bab371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5840e3bd1a174750a63285ec1294f6ee","placeholder":"​","style":"IPY_MODEL_47c5f850a4f547d2853fde8e405ff29f","value":"Upload file pytorch_model.bin: 100%"}},"e32c662e83304ecc8b0679a1e078654c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d34826bf3c45068ecc77156f45077a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df6e5b2ff4004e88967b9bf0d9bab371","IPY_MODEL_67462b829f134d50a932ec0aff9bd615","IPY_MODEL_02f8dbaba159423fa0929b4bec0b88fe"],"layout":"IPY_MODEL_e32c662e83304ecc8b0679a1e078654c"}},"e9fe45d20b9b460c8a3bb551748b5e32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea27026425a348e58cc0c8a7f6c4eba7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea32840fc60043838abf2397affb6a48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f225d643bef84e26a056ce1e7a315364":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8385a8265b44c94b000c94ace9f35c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de93c4b320774770837b951739958424","placeholder":"​","style":"IPY_MODEL_f225d643bef84e26a056ce1e7a315364","value":"<center>\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.svg alt='Hugging Face'>\n<br>\nCopy a token from <a href=\"https://huggingface.co/settings/token\" target=\"_blank\">your Hugging Face tokens page</a> and paste it below.\n<br>\nImmediately click login after copying your token or it might be stored in plain text in this notebook file.\n</center>"}},"fbaf95a972544978b516c6731fcaf6e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd7d51ca6b2e4912a8da41ac1dcaba35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
